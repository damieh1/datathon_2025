{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DFZrd49HuxH"
      },
      "outputs": [],
      "source": [
        "# Load Libraries\n",
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Change filename after uploading the data*\n",
        "\n",
        "â–¶ Codeline: df = pd.read_csv(\"/content/sample_data/ENTER_FILE_NAME.csv\")"
      ],
      "metadata": {
        "id": "V5JoPxJu2eDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your Bright Data output file\n",
        "df = pd.read_csv(\"/content/sample_data/brightdata.csv\")\n",
        "\n",
        "# Define your search terms (case-insensitive)\n",
        "keywords = [\"jew\", \"netanyahu\", \"#gaza\", \"Zionist\", \"Israel\", \"settlers\"]  # ðŸ‘ˆ Edit this list as needed\n",
        "\n",
        "# Storage for filtered results\n",
        "parsed_rows = []\n",
        "text_id = 1\n",
        "\n",
        "# Iterate through each row\n",
        "for _, row in df.iterrows():\n",
        "    try:\n",
        "        username = row.get(\"id\", \"\")\n",
        "        posts_raw = row.get(\"posts\", \"\")\n",
        "\n",
        "        if not posts_raw or pd.isna(posts_raw):\n",
        "            continue\n",
        "\n",
        "        # Safely parse JSON from the 'posts' column\n",
        "        try:\n",
        "            posts = json.loads(posts_raw)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"JSON decode error: {e}\")\n",
        "            print(f\"Raw content preview: {posts_raw[:300]}\\n\")\n",
        "            continue\n",
        "\n",
        "        for post in posts:\n",
        "            description = post.get(\"description\", \"\")\n",
        "            tweet_id = post.get(\"post_id\", \"\")\n",
        "            date_posted = post.get(\"date_posted\", \"\")\n",
        "\n",
        "            if description and tweet_id:\n",
        "                if any(kw.lower() in description.lower() for kw in keywords):\n",
        "                    parsed_rows.append({\n",
        "                        \"text_id\": text_id,\n",
        "                        \"Text\": description,\n",
        "                        \"tweet_id\": tweet_id,\n",
        "                        \"Username\": username,\n",
        "                        \"date_posted\": date_posted\n",
        "                    })\n",
        "                    text_id += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error: {e}\")\n",
        "\n",
        "# Save the filtered output\n",
        "df_out = pd.DataFrame(parsed_rows)\n",
        "df_out.to_csv(\"/content/sample_data/parsed_tweets_filtered.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# Shows you how much Tweets your collection already contains\n",
        "print(f\"Parsing complete. {len(df_out)} relevant tweets saved.\")\n"
      ],
      "metadata": {
        "id": "8DH8dwvcujdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â–¶ **Convert Output from Script above into Compatible Format for the Annotation**"
      ],
      "metadata": {
        "id": "wOEZbvarUY3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the uploaded file\n",
        "# Adjust the path if necessary â€” this assumes you're using the default Colab folders\n",
        "parsed_df = pd.read_csv(\"/content/sample_data/parsed_tweets_filtered.csv\")\n",
        "\n",
        "# Step 2: Transform into the required format\n",
        "transformed_df = parsed_df.rename(columns={\"tweet_id\": \"TweetID\"})[[\"TweetID\", \"Username\"]]\n",
        "\n",
        "# Step 3: Save and download the result\n",
        "output_file = \"/content/sample_data/parsed_tweets_for_annotation.csv\"\n",
        "transformed_df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "id": "Jnp6qMf4Io_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BF_st6gu9RJw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}